## global settings
trace.enable=false
log.enable=false
sample.ratio=1
trace.probeType=SRV
trace.entrance=SRV

## file|kafka|msgFrame
msg.sender=kafka
msg.sender.trace.topic=cmos-logger-test1
msg.sender.log.topic=cmos-logger-test1
msg.sender.batch.size=1

## Kafka settings

kafka.metadata.broker.list=192.168.100.105:9092,192.168.100.106:9092,192.168.100.107:9092

kafka.request.required.acks=-1
kafka.producer.type=async
kafka.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.value.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.serializer.class=kafka.serializer.StringEncoder
kafka.compression.type=snappy
kafka.queue.buffering.max.ms=1000
kafka.queue.buffering.max.messages=50000
kafka.batch.num.messages=10000
kafka.queue.enqueue.timeout.ms=0
kafka.serializer.encoding=UTF-8

## logfile settings, if msg.sender=file
msg.logfile.dir=/workspace/asiainfo/log4x-nj/logtest/
msg.logfile.maxFileSize=100

## max message queue size
msg.queue.size=100000
## if matched, drop the messages
msg.content.filter=CheckSVImpl.heartbeat

#debug.enable=true

## app.server.ip 
app.server.ip.config=test

# \u76D1\u63A7\u65E5\u5FD7\u53D1\u9001\u9891\u7387
monitor.log.interval.ms=100


#Switch of the flush error message, if true the message not produced or not correct finish will be sent to analyser
#flush.error.message.enable=false
#\u65E5\u5FD7\u6587\u4EF6\u8DEF\u5F84
failover.filename=../logs/cmos-logger.log
#\u6EDA\u52A8\u65E5\u5FD7\u6587\u4EF6\u6A21\u5F0F
failover.file.pattern=D:/logs/cmos-logger-%{yyyy-MM-dd-HH-mm-ss}.log
#\u65E5\u5FD7\u6EDA\u52A8\u9891\u7387\uFF08\u4EC5\u5BF9TimeRollingFileWriter\u6709\u6548\uFF09
failover.date.pattern=HH_mm
#\u65E5\u5FD7\u6EDA\u52A8\u5927\u5C0F\u9600\u503C\uFF0C\u5355\u4F4D\u5B57\u8282\uFF08\u4EC5FixedSizeAppendFileWriter\u6709\u6548\uFF09
failover.log.threshold=102400
#\u672C\u5730\u65E5\u5FD7\u6587\u4EF6\u5199\u5165\u5B9E\u73B0
failover.writer=com.cmos.core.logger.file.TimeRollingFileWriter

bus.log.level=info